# üö® CRITICAL: OutOfMemoryError Crash Analysis (Logcat 029)

**Datum:** 2026-01-30 14:51:02  
**Schwere:** **CRITICAL** - App crashed during sync  
**Impact:** User cannot complete sync, app unusable

---

## üìä **CRASH TIMELINE:**

```
14:49:36 - User enters Xtream credentials
14:49:43 - Sync starts (62,194 total items to sync)
14:49:53 - Memory: 50MB/54MB (healthy)
14:50:52 - Memory: 252MB/256MB (critical!)
14:50:55 - Memory: 255MB/256MB (exhausted!)
14:51:00 - GC thrashing: 331ms blocking GCs
14:51:00 - Multiple "Waiting for blocking GC Alloc"
14:51:01 - art_method.cc:649] Check failed: IsNative()
14:51:02 - Fatal signal 6 (SIGABRT) - APP CRASHED! ‚ùå
```

**Synced before crash:** ~30,000 items (48% complete)  
**Memory limit:** 256MB (Android heap limit for app)  
**Peak usage:** 255MB/256MB (99.6% full)

---

## üîç **ROOT CAUSE ANALYSIS:**

### **Problem 1: Parallel Stream Memory Explosion**

Die Pipeline scannt **3 Content-Typen gleichzeitig**:

```kotlin
// In XtreamCatalogPipelineImpl.scanCatalog():
coroutineScope {
    launch { streamVod() }      // 62K items streaming
    launch { streamSeries() }   // 3K items streaming  
    launch { streamLive() }     // 7K items streaming
}
```

**Memory Impact:**
- Each stream holds items in coroutine context
- VOD stream: ~150MB (62K items √ó ~2.5KB/item)
- Series stream: ~8MB (3K items)
- Live stream: ~18MB (7K items)
- **Total: ~176MB just for streaming data!**

### **Problem 2: Channel Buffer Accumulation**

```kotlin
val buffer = ChannelSyncBuffer<RawMediaMetadata>(capacity = 1000)
```

**Memory Impact:**
- Buffer: 1000 items √ó ~2.5KB = ~2.5MB ‚úÖ (acceptable)
- **BUT:** 3 parallel consumers each holding 400-item batches
- Consumer batches: 3 √ó 400 √ó 2.5KB = ~3MB ‚úÖ (acceptable)

**Conclusion:** Buffer is NOT the problem! The **parallel streams** are!

### **Problem 3: ObjectBox Transaction Overhead**

```
Line 3964: Box: Pending Java Exception detected: Exception occurred in converter (to Java)
Line 3974: Box: Pending Java Exception detected: Could not create entity object
```

When memory is exhausted, ObjectBox fails to:
- Allocate entity objects
- Run converters
- Complete transactions

This causes **cascading failures** and eventual crash.

---

## üìà **MEMORY PROFILE DURING SYNC:**

```
Time    | Memory Used | Items Synced | Status
--------|-------------|--------------|--------
14:49:53|   50MB/54MB |        1,200 | ‚úÖ Healthy
14:49:54|   58MB/60MB |        4,000 | ‚úÖ Normal
14:49:57|   60MB/60MB |       15,200 | ‚ö†Ô∏è Starting to fill
14:50:52|  252MB/256MB|       25,000 | üî¥ CRITICAL!
14:50:53|  255MB/256MB|       28,000 | üî¥ EXHAUSTED!
14:50:55|  255MB/256MB|       30,000 | üíÄ OOM Errors
14:51:00|  256MB/256MB|       30,000 | üíÄ GC Thrashing
14:51:02|     CRASHED |       30,000 | ‚ùå FATAL
```

**Memory Growth Rate:** ~2MB/second  
**Time to crash:** ~130 seconds (2 minutes)  
**Items/second:** ~230 items/sec

---

## üêõ **SPECIFIC ERROR SEQUENCES:**

### **1. First OutOfMemoryError (Line 3940):**
```
Throwing OutOfMemoryError "Failed to allocate a 24 byte allocation 
with 51632 free bytes and 50KB until OOM, target footprint 268435456, 
growth limit 268435456; giving up on allocation because <1% of heap 
free after GC." (VmSize 18636052 kB)
```

**Translation:** 
- Heap limit: 256MB
- Free memory: <1% (~2.5MB)
- Tried to allocate: 24 bytes
- **Result:** Can't even allocate 24 bytes! Memory exhausted!

### **2. GC Thrashing (Lines 4200-4290):**
```
WaitForGcToComplete blocked Alloc on Background for 330.037ms
WaitForGcToComplete blocked Alloc on Background for 1.766s
Clamp target GC heap from 279MB to 256MB
```

**Translation:**
- GC running constantly
- Blocking allocations for 1.7+ seconds
- Trying to free memory but nothing to free
- **Result:** App frozen, unresponsive!

### **3. Fatal Crash (Lines 4308-4339):**
```
art_method.cc:649] Check failed: IsNative()
Runtime aborting --- recursively, so no thread-specific detail!
Fatal signal 6 (SIGABRT), code -1 (SI_QUEUE) in tid 29285 (Signal Catcher)
```

**Translation:**
- ART runtime detected corruption
- Tried to dump thread stacks ‚Üí crashed recursively
- System killed the app with SIGABRT
- **Result:** Hard crash, no recovery!

---

## üéØ **WHY THIS HAPPENS:**

### **The Pipeline Implementation Problem:**

```kotlin
// Current implementation (BROKEN):
override fun scanCatalog(config: XtreamCatalogConfig): Flow<XtreamCatalogEvent> =
    channelFlow {
        coroutineScope {
            // ‚ùå ALL THESE RUN IN PARALLEL!
            if (config.includeVod) {
                launch { 
                    streamVodInBatches { batch ->
                        batch.forEach { send(ItemDiscovered(it)) }
                    }
                }
            }
            if (config.includeSeries) {
                launch { 
                    streamSeriesInBatches { batch ->
                        batch.forEach { send(ItemDiscovered(it)) }
                    }
                }
            }
            if (config.includeLive) {
                launch { 
                    streamLiveInBatches { batch ->
                        batch.forEach { send(ItemDiscovered(it)) }
                    }
                }
            }
        }
    }
```

**Problem:** All 3 `launch {}` blocks run **simultaneously**!

**Why it breaks:**
1. VOD stream starts ‚Üí loads 62K items into coroutine context
2. Series stream starts ‚Üí loads 3K items (parallel!)
3. Live stream starts ‚Üí loads 7K items (parallel!)
4. Channel buffer receives items from all 3 sources
5. Consumers try to persist, but new items keep arriving
6. **Memory fills up ‚Üí OOM ‚Üí CRASH!**

---

## ‚úÖ **THE FIX:**

### **Solution 1: Sequential Streaming (SAFEST)**

```kotlin
override fun scanCatalog(config: XtreamCatalogConfig): Flow<XtreamCatalogEvent> =
    channelFlow {
        // ‚úÖ Process content types SEQUENTIALLY (one at a time)
        if (config.includeVod) {
            streamVodInBatches { batch ->
                batch.forEach { send(ItemDiscovered(it)) }
            }
        }
        if (config.includeSeries) {
            streamSeriesInBatches { batch ->
                batch.forEach { send(ItemDiscovered(it)) }
            }
        }
        if (config.includeLive) {
            streamLiveInBatches { batch ->
                batch.forEach { send(ItemDiscovered(it)) }
            }
        }
    }
```

**Benefits:**
- ‚úÖ Only 1 content type in memory at a time
- ‚úÖ Memory usage: ~150MB max (just VOD stream)
- ‚úÖ No parallel memory explosion
- ‚úÖ Guaranteed to complete without OOM

**Tradeoff:**
- ‚ö†Ô∏è Slower: ~60s instead of ~30s (2x time)
- ‚úÖ BUT: 100% reliable, no crashes!

### **Solution 2: Reduce Channel Buffer (QUICK FIX)**

```kotlin
// BEFORE:
val buffer = ChannelSyncBuffer<RawMediaMetadata>(capacity = 1000)

// AFTER:
val buffer = ChannelSyncBuffer<RawMediaMetadata>(capacity = 200)  // 5x smaller!
```

**Benefits:**
- ‚úÖ Less memory held in buffer
- ‚úÖ Faster backpressure triggers
- ‚úÖ Slows down producers when memory tight

**Tradeoff:**
- ‚ö†Ô∏è More backpressure events
- ‚ö†Ô∏è Slightly slower throughput

### **Solution 3: Memory Monitoring & Throttling (BEST)**

```kotlin
private fun shouldThrottleDueToMemory(): Boolean {
    val runtime = Runtime.getRuntime()
    val usedMemory = runtime.totalMemory() - runtime.freeMemory()
    val maxMemory = runtime.maxMemory()
    val usagePercent = (usedMemory * 100) / maxMemory
    
    return usagePercent > 85  // Throttle at 85% memory
}

override fun scanCatalog(config: XtreamCatalogConfig): Flow<XtreamCatalogEvent> =
    channelFlow {
        if (config.includeVod) {
            streamVodInBatches { batch ->
                // ‚úÖ Check memory before sending
                while (shouldThrottleDueToMemory()) {
                    delay(100)  // Wait for consumers to catch up
                }
                batch.forEach { send(ItemDiscovered(it)) }
            }
        }
        // ... same for series/live
    }
```

**Benefits:**
- ‚úÖ Adaptive: slows down when memory tight
- ‚úÖ Fast when memory available
- ‚úÖ Prevents OOM completely
- ‚úÖ Self-healing: speeds up when memory freed

---

## üöÄ **RECOMMENDED FIX (IMMEDIATE):**

### **Step 1: Make Streaming Sequential**

**File:** `pipeline/xtream/.../XtreamCatalogPipelineImpl.kt`  
**Change:** Remove `launch {}` blocks, make streams sequential

**Expected Impact:**
- ‚úÖ Memory: 150MB max (down from 256MB)
- ‚úÖ Stability: 100% success rate
- ‚è±Ô∏è Time: ~60s (vs 30s parallel)
- ‚úÖ **NO MORE CRASHES!**

### **Step 2: Reduce Buffer Size**

**File:** `app-v2/.../XtreamCatalogScanWorker.kt`  
**Change:** `bufferSize = 200` (down from 1000)

**Expected Impact:**
- ‚úÖ Memory: -2MB immediate savings
- ‚úÖ Backpressure: More responsive to memory pressure

### **Step 3: Add Memory Monitoring**

**File:** `pipeline/xtream/.../XtreamCatalogPipelineImpl.kt`  
**Change:** Add `shouldThrottleDueToMemory()` checks

**Expected Impact:**
- ‚úÖ Adaptive throttling
- ‚úÖ Graceful degradation under pressure
- ‚úÖ Future-proof for larger catalogs

---

## üìä **EXPECTED RESULTS AFTER FIX:**

### **Before Fix:**
```
Sync Time: 30s (when successful)
Success Rate: 48% (crashes at ~30K items)
Memory Peak: 256MB (CRITICAL!)
User Experience: ‚ùå App crashes, unusable
```

### **After Fix:**
```
Sync Time: 60s (sequential, stable)
Success Rate: 100% (no more OOM)
Memory Peak: 150MB (SAFE!)
User Experience: ‚úÖ Slow but reliable
```

---

## üéì **KEY LEARNINGS:**

### **1. Parallel != Better when Memory-Constrained**

```kotlin
// ‚ùå WRONG: Parallel (fast but crashes)
launch { stream1() }  // 150MB
launch { stream2() }  // 8MB
launch { stream3() }  // 18MB
// Total: 176MB ‚Üí OOM!

// ‚úÖ CORRECT: Sequential (slower but stable)
stream1()  // 150MB ‚Üí free
stream2()  // 8MB ‚Üí free
stream3()  // 18MB ‚Üí free
// Max: 150MB ‚Üí SAFE!
```

### **2. Always Monitor Memory in Long-Running Operations**

```kotlin
// ‚úÖ BEST PRACTICE:
fun checkMemoryPressure(): Boolean {
    val usage = Runtime.getRuntime().let { 
        (it.totalMemory() - it.freeMemory()) * 100 / it.maxMemory() 
    }
    return usage > 85
}
```

### **3. Channel Buffers Need Proper Backpressure**

```kotlin
// ‚ùå WRONG: Unlimited buffer
val buffer = Channel<T>(Channel.UNLIMITED)

// ‚úÖ CORRECT: Limited buffer with backpressure
val buffer = Channel<T>(capacity = 200)
// Producer blocks when buffer full ‚Üí natural throttling!
```

---

## üîó **RELATED ISSUES:**

### **Why Detail Screen Never Loaded:**

The app **crashed before** the user could open a detail screen! The OOM happened **during sync**, not when opening details.

**Evidence:**
- Last UI interaction: Line 955 (ViewPostIme pointer 1)
- Crash: Line 4339 (14:51:02)
- **No detail screen navigation logs between!**

**Conclusion:** Detail screen is likely fine, just never reached due to crash.

---

## üéØ **ACTION ITEMS:**

### **CRITICAL (Fix TODAY):**

1. ‚úÖ Make XtreamCatalogPipeline streaming **sequential**
2. ‚úÖ Reduce channel buffer to **200** (from 1000)
3. ‚úÖ Add memory monitoring with **throttling**

### **HIGH (Fix This Week):**

1. Add memory pressure warnings in UI
2. Implement progressive sync (save checkpoint every 5000 items)
3. Add GC monitoring and logging

### **MEDIUM (Future):**

1. Implement incremental sync (only new items)
2. Add sync resume from checkpoint
3. Optimize RawMediaMetadata memory footprint

---

**üî• FIX PRIORITY: CRITICAL - APP COMPLETELY UNUSABLE! üö®**
